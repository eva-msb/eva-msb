<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>EVA-M SCHMIDT // LLM SOCIAL PREFERENCES</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="../assets/css/style.css" />
</head>
<body>

  <div class="project-page">

    <!-- Back button -->
    <a href="../index.html" class="back-button">← Back</a>

    <div class="project-layout">
      
      <!-- LEFT: PHOTO + JOURNAL/YEAR -->
      <div class="project-media">
        <div class="project-photo-large">
          <img src="../assets/img/llm_social_prefs.png" alt="Legal DM">
        </div>
        <div class="project-journal">
          <a href="https://www.nature.com/articles/s41598-024-73306-x" target="_blank" rel="noopener noreferrer" class="journal-link">
            <span>SCIENTIFIC REPORTS //</span><br>
            <span>2024</span>
          </a>
        </div>
      </div>

      <!-- RIGHT: TITLE, KEYWORDS, ABSTRACT -->
      <div class="project-info">
        <div class="project-info-line"></div>

        <h1 class="project-title">
          LLM SOCIAL PREFERENCES
        </h1>

        <p class="project-keywords">
          Keyword // Keyword // Keyword // Keyword // Keyword
        </p>

        <p class="project-abstract">
          Pre-trained LLMs have garnered significant attention for their 
          ability to generate human-like text and responses across various domains. This study 
          delves into examines the social and strategic behavior of the commonly used LLM GPT-3.5 
          by investigating its suggestions in well-established behavioral economics paradigms. 
          Specifically, we focus on social preferences, including altruism, reciprocity, and 
          fairness, in the context of two classic economic games: the Dictator Game (DG) and 
          the Ultimatum Game (UG). Our research aims to answer three overarching questions: 
          (1) To what extent do GPT-3.5 suggestions reflect human social preferences? (2) 
          How do socio-demographic features of the advisee and (3) technical parameters of 
          the model influence the suggestions of GPT-3.5? We present detailed empirical evidence 
          from extensive experiments with GPT-3.5, analyzing its responses to various game 
          scenarios while manipulating the demographics of the advisee and the model temperature. 
          Our findings reveal that, in the DG Dictator Game, model suggestions are more altruistic 
          than in humans. We further show that it also picks up on more subtle aspects of human 
          social preferences: fairness and reciprocity. This research contributes to the 
          ongoing exploration of AI-driven systems’ alignment with human behavior and 
          social norms, providing valuable insights into the behavior of pre-trained 
          LLMs and their implications for human-AI interactions. Additionally, our study 
          offers a methodological benchmark for future research examining human-like 
          characteristics and behaviors in language models.
        </p>
      </div>
    </div>

  </div>

</body>
</html>
